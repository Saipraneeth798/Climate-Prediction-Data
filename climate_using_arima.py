# -*- coding: utf-8 -*-
"""Climate using Arima.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12-zmBvfwiZ_Vr9s2wRvzihvU9Vmcf_bE
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from google.colab import files
import seaborn as sns



import statsmodels.api as sm
from statsmodels.tsa.stattools import adfuller, acf, pacf
from statsmodels.graphics.tsaplots import plot_acf, plot_pacf
from statsmodels.graphics.gofplots import qqplot


from sklearn.metrics import mean_squared_error
from math import sqrt
import warnings
warnings.filterwarnings("ignore")

# %matplotlib inline

df=pd.read_csv('/content/climate test.csv')
df.head()

df.isnull().sum()

df.describe()

df.dtypes

float_columns=df.select_dtypes(include=['float64']).columns
print("Float columns:", float_columns) # Use the correct variable name 'float_columns'

from sklearn.model_selection import train_test_split

X = df.drop('date', axis=1)
y = df['meantemp']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

df.plot(figsize=(12,5),title=' Mean Temperature', x='date', y='meantemp').autoscale(axis='x',tight=True)

sns.lineplot(df.drop('date',axis=1))
plt.xlabel('date')
plt.ylabel('meantemp')

sns.lineplot(df.date)
plt.xlabel('date')
plt.ylabel('meantemp')
plt.title('Average pressure')

pivot = pd.pivot_table(df, values='meantemp', index='date', aggfunc='mean')
pivot.plot(figsize=(20,6))
plt.title('Yearly temperatures')
plt.xlabel('Date')
plt.ylabel('Meantemp')
plt.legend().remove()
plt.show()

train = df[:-60].copy()
val = df[-60:-12].copy()
test = df[-12:].copy()

baseline = val['meantemp'].shift()
baseline.dropna(inplace=True)
baseline.head()

def check_stationarity(y, lags_plots=48, figsize=(22,8)):
    "Use Series as parameter"

    # Handle missing or infinite data
    y = pd.Series(y).dropna()  # Drop missing values
    y = y.replace([np.inf, -np.inf], np.nan).dropna()  # Replace infinite values with NaN, then drop NaNs

    # Creating plots of the DF
    fig = plt.figure()

    ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=2)
    ax2 = plt.subplot2grid((3, 3), (1, 0))
    ax3 = plt.subplot2grid((3, 3), (1, 1))
    ax4 = plt.subplot2grid((3, 3), (2, 0), colspan=2)

    y.plot(ax=ax1, figsize=figsize)
    ax1.set_title(' Temperature Variation')
    plot_acf(y, lags=lags_plots, zero=False, ax=ax2);
    plot_pacf(y, lags=lags_plots, zero=False, ax=ax3);
    sns.distplot(y, bins=int(sqrt(len(y))), ax=ax4)
    ax4.set_title('Distribution Chart')

    plt.tight_layout()

    print('Results of Dickey-Fuller Test:')
    adfinput = adfuller(y)
    adftest = pd.Series(adfinput[0:4], index=['Test Statistic','p-value','Lags Used','Number of Observations Used'])
    adftest = round(adftest,4)

    for key, value in adfinput[4].items():
        adftest["Critical Value (%s)"%key] = value.round(4)

    print(adftest)

    if adftest[0].round(2) < adftest[5].round(2):
        print('\nThe Test Statistics is lower than the Critical Value of 5%.\nThe serie seems to be stationary')
    else:
        print("\nThe Test Statistics is higher than the Critical Value of 5%.\nThe serie isn't stationary")



def check_stationarity(y, lags_plots=None, figsize=(22,8)):
    "Use Series as parameter"

    # Handle missing or infinite data
    y = pd.Series(y).dropna()  # Drop missing values
    y = y.replace([np.inf, -np.inf], np.nan).dropna()  # Replace infinite values with NaN, then drop NaNs

    # Determine appropriate number of lags if not provided
    if lags_plots is None:
        lags_plots = min(10 * np.log10(len(y)), len(y) // 2 - 1)

    # Creating plots of the DF
    fig = plt.figure()

    ax1 = plt.subplot2grid((3, 3), (0, 0), colspan=2)
    ax2 = plt.subplot2grid((3, 3), (1, 0))
    ax3 = plt.subplot2grid((3, 3), (1, 1))
    ax4 = plt.subplot2grid((3, 3), (2, 0), colspan=2)

    y.plot(ax=ax1, figsize=figsize)
    ax1.set_title(' Temperature Variation')
    plot_acf(y, lags=lags_plots, zero=False, ax=ax2);
    plot_pacf(y, lags=lags_plots, zero=False, ax=ax3); # Use calculated lags_plots
    sns.distplot(y, bins=int(sqrt(len(y))), ax=ax4)
    ax4.set_title('Distribution Chart')

    plt.tight_layout()

    print('Results of Dickey-Fuller Test:')
    adfinput = adfuller(y)
    adftest = pd.Series(adfinput[0:4], index=['Test Statistic','p-value','Lags Used','Number of Observations Used'])
    adftest = round(adftest,4)

    for key, value in adfinput[4].items():
        adftest["Critical Value (%s)"%key] = value.round(4)

    print(adftest)

    if adftest[0].round(2) < adftest[5].round(2):
        print('\nThe Test Statistics is lower than the Critical Value of 5%.\nThe serie seems to be stationary')
    else:
        print("\nThe Test Statistics is higher than the Critical Value of 5%.\nThe serie isn't stationary")

# The first approach is to check the series without any transformation
check_stationarity(train['meantemp'])

def adf_test(series):
    result = adfuller(series)
    p_value = result[1]
    if p_value < 0.05:
        print("The series is stationary (p < 0.05)")
    else:
        print("The series is non-stationary (p >= 0.05)")
    return p_value

plt.figure(figsize=(12,6))
plt.plot(train['meantemp'], label='Original Data')
plt.title("Original Data")
plt.show()

print("ADF Test on Original Data:")
adf_test(train['meantemp'])

data = train['meantemp']
data_diff = data.diff().dropna()
print("\nADF Test on Differenced Data:")
adf_test(data_diff)

plt.figure(figsize=(12,6))
plt.plot(data_diff, label='Differenced Data', color='orange')
plt.title("Differenced Data")
plt.show()

data_log = np.log(data[data > 0])
data_log_diff = data_log.diff().dropna()
print("\nADF Test on Log Differenced Data:")
adf_test(data_log_diff)

plt.figure(figsize=(12,6))
plt.plot(data_log_diff, label='Log Differenced Data', color='green')
plt.title("Log Differenced Data")
plt.show()

!pip install statsmodels
from statsmodels.tsa.arima.model import ARIMA
# Assuming 'train' is the DataFrame containing 'AverageTemperature'
model = ARIMA(train['meantemp'], order=(5, 1, 0))  # Reference the column within the DataFrame
model_fit = model.fit()
print(model_fit.summary())

sns.lineplot(y_train)
sns.lineplot(y_test)
sns.lineplot(predictions)
plt.title('Model predictions based on linear regression')

forecast_steps = 12  # Forecast for the next 12 months
forecast = model_fit.get_forecast(steps=forecast_steps)

# Plot the results
plt.figure(figsize=(10,6))
plt.plot(train['meantemp'], label='Train')  # Plot only the numerical column
plt.plot(test['meantemp'], label='Test')  # Plot only the numerical column

# Extract the forecasted values and confidence intervals
arima_forecast = forecast.predicted_mean
arima_conf_int = forecast.conf_int()

# Plot the forecast
plt.plot(test.index, arima_forecast, label='ARIMA Forecast')
plt.fill_between(test.index, arima_conf_int.iloc[:, 0], arima_conf_int.iloc[:, 1], alpha=0.2)  # Add confidence interval

plt.legend()
plt.show()

def measure_rmse(y_true, y_pred):
    # Ensure both y_true and y_pred are numeric by converting them to floats.
    y_true = y_true.astype(float)
    y_pred = y_pred.astype(float)
    return sqrt(mean_squared_error(y_true,y_pred))

# Using the function with the baseline values, selecting 'AverageTemperature' column
rmse_base = measure_rmse(val.iloc[1:,1],baseline)  # Use column index 1 for 'AverageTemperature'
print(f'The RMSE of the baseline that we will try to diminish is {round(rmse_base,4)} celsius degrees')

from sklearn.metrics import mean_squared_error,mean_absolute_error
from statsmodels.tsa.arima.model import ARIMA

# Assuming 'train' is the DataFrame containing 'AverageTemperature'
model = ARIMA(train['meantemp'], order=(5, 1, 0))  # Reference the column within the DataFrame
model_fit = model.fit()

# Generate predictions
# Replace with the actual start and end index or dates for your test set
start_index = 0
end_index = len(test) - 1
predictions = model_fit.predict(start=start_index, end=end_index)

# 'predictions' now holds the model predictions and 'test' is your test DataFrame
# with a column named 'AverageTemperature'
print('MEA:',mean_absolute_error(test['meantemp'], predictions))
print('MSE:',mean_squared_error(test['meantemp'], predictions))
print('RMSE:',np.sqrt(mean_squared_error(test['meantemp'], predictions)))

from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression # Changed model to LinearRegression
from sklearn.metrics import mean_squared_error # Changed metric to mean_squared_error


X = df.drop('date', axis=1)
y = df['meantemp']

# Split data into training and test sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a simple Linear Regression model # Changed model to LinearRegression
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Evaluate the model
mse = mean_squared_error(y_test, y_pred) # Changed metric to mean_squared_error
print(f"Model Mean Squared Error: {mse:.2f}")

import pickle

with open("model.pkl", "wb") as f:
    pickle.dump(model, f)

with open("model.pkl", "rb") as f:
    model = pickle.load(f)

import pickle
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
# Use LinearRegression for continuous target variables
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error # Changed to appropriate metric for regression

# Load dataset
X = df.drop('date', axis=1)
y = df['meantemp']

# Split the dataset
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Train a Linear Regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Save the trained model to a Pickle file
with open('trained_model.pkl', 'wb') as file:
    pickle.dump(model, file)

# Load the trained model from the Pickle file
with open('trained_model.pkl', 'rb') as file:
    loaded_model = pickle.load(file)

# Verify the type of the loaded model
print(type(loaded_model))  # Should be <class 'sklearn.linear_model._linear.LinearRegression'>

# Use the loaded model for predictions
predictions = loaded_model.predict(X_test)

# Print predictions
print(predictions)

# Evaluate the model using mean squared error
mse = mean_squared_error(y_test, predictions)
print(f"Model Mean Squared Error: {mse:.2f}")